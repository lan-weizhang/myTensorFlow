{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0, Testing Accuracy0.951, Training Accuracy0.953473, Learning Rate=0.001\n",
      "Iter1, Testing Accuracy0.9631, Training Accuracy0.968018, Learning Rate=0.00095\n",
      "Iter2, Testing Accuracy0.9663, Training Accuracy0.976273, Learning Rate=0.0009025\n",
      "Iter3, Testing Accuracy0.9685, Training Accuracy0.981655, Learning Rate=0.000857375\n",
      "Iter4, Testing Accuracy0.9732, Training Accuracy0.985727, Learning Rate=0.000814506\n",
      "Iter5, Testing Accuracy0.9768, Training Accuracy0.988745, Learning Rate=0.000773781\n",
      "Iter6, Testing Accuracy0.9766, Training Accuracy0.990109, Learning Rate=0.000735092\n",
      "Iter7, Testing Accuracy0.976, Training Accuracy0.9908, Learning Rate=0.000698337\n",
      "Iter8, Testing Accuracy0.9773, Training Accuracy0.992036, Learning Rate=0.00066342\n",
      "Iter9, Testing Accuracy0.9769, Training Accuracy0.992818, Learning Rate=0.000630249\n",
      "Iter10, Testing Accuracy0.9788, Training Accuracy0.993855, Learning Rate=0.000598737\n",
      "Iter11, Testing Accuracy0.9782, Training Accuracy0.994218, Learning Rate=0.0005688\n",
      "Iter12, Testing Accuracy0.9801, Training Accuracy0.995255, Learning Rate=0.00054036\n",
      "Iter13, Testing Accuracy0.9798, Training Accuracy0.995564, Learning Rate=0.000513342\n",
      "Iter14, Testing Accuracy0.9805, Training Accuracy0.995818, Learning Rate=0.000487675\n",
      "Iter15, Testing Accuracy0.9798, Training Accuracy0.996073, Learning Rate=0.000463291\n",
      "Iter16, Testing Accuracy0.9819, Training Accuracy0.996291, Learning Rate=0.000440127\n",
      "Iter17, Testing Accuracy0.9794, Training Accuracy0.995655, Learning Rate=0.00041812\n",
      "Iter18, Testing Accuracy0.9811, Training Accuracy0.996491, Learning Rate=0.000397214\n",
      "Iter19, Testing Accuracy0.9799, Training Accuracy0.996218, Learning Rate=0.000377354\n",
      "Iter20, Testing Accuracy0.9809, Training Accuracy0.9964, Learning Rate=0.000358486\n",
      "Iter21, Testing Accuracy0.9825, Training Accuracy0.996691, Learning Rate=0.000340562\n",
      "Iter22, Testing Accuracy0.982, Training Accuracy0.996818, Learning Rate=0.000323534\n",
      "Iter23, Testing Accuracy0.9827, Training Accuracy0.996927, Learning Rate=0.000307357\n",
      "Iter24, Testing Accuracy0.9811, Training Accuracy0.997055, Learning Rate=0.000291989\n",
      "Iter25, Testing Accuracy0.9815, Training Accuracy0.997127, Learning Rate=0.00027739\n",
      "Iter26, Testing Accuracy0.9821, Training Accuracy0.997182, Learning Rate=0.00026352\n",
      "Iter27, Testing Accuracy0.9814, Training Accuracy0.997255, Learning Rate=0.000250344\n",
      "Iter28, Testing Accuracy0.981, Training Accuracy0.997055, Learning Rate=0.000237827\n",
      "Iter29, Testing Accuracy0.9829, Training Accuracy0.997309, Learning Rate=0.000225936\n",
      "Iter30, Testing Accuracy0.9821, Training Accuracy0.9974, Learning Rate=0.000214639\n",
      "Iter31, Testing Accuracy0.9823, Training Accuracy0.997436, Learning Rate=0.000203907\n",
      "Iter32, Testing Accuracy0.983, Training Accuracy0.997436, Learning Rate=0.000193711\n",
      "Iter33, Testing Accuracy0.9819, Training Accuracy0.997473, Learning Rate=0.000184026\n",
      "Iter34, Testing Accuracy0.9817, Training Accuracy0.997491, Learning Rate=0.000174825\n",
      "Iter35, Testing Accuracy0.9828, Training Accuracy0.997491, Learning Rate=0.000166083\n",
      "Iter36, Testing Accuracy0.9821, Training Accuracy0.997564, Learning Rate=0.000157779\n",
      "Iter37, Testing Accuracy0.9826, Training Accuracy0.997618, Learning Rate=0.00014989\n",
      "Iter38, Testing Accuracy0.9828, Training Accuracy0.997636, Learning Rate=0.000142396\n",
      "Iter39, Testing Accuracy0.9832, Training Accuracy0.997673, Learning Rate=0.000135276\n",
      "Iter40, Testing Accuracy0.9829, Training Accuracy0.997691, Learning Rate=0.000128512\n",
      "Iter41, Testing Accuracy0.9832, Training Accuracy0.997691, Learning Rate=0.000122087\n",
      "Iter42, Testing Accuracy0.9824, Training Accuracy0.997709, Learning Rate=0.000115982\n",
      "Iter43, Testing Accuracy0.9827, Training Accuracy0.997727, Learning Rate=0.000110183\n",
      "Iter44, Testing Accuracy0.9823, Training Accuracy0.997764, Learning Rate=0.000104674\n",
      "Iter45, Testing Accuracy0.9833, Training Accuracy0.997764, Learning Rate=9.94403e-05\n",
      "Iter46, Testing Accuracy0.9827, Training Accuracy0.997782, Learning Rate=9.44682e-05\n",
      "Iter47, Testing Accuracy0.9829, Training Accuracy0.9978, Learning Rate=8.97448e-05\n",
      "Iter48, Testing Accuracy0.9827, Training Accuracy0.997818, Learning Rate=8.52576e-05\n",
      "Iter49, Testing Accuracy0.9825, Training Accuracy0.997855, Learning Rate=8.09947e-05\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#载入数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "#每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义placeholder\n",
    "x = tf.placeholder(tf.float32, [None,784])\n",
    "y = tf.placeholder(tf.float32, [None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "lr = tf.Variable(0.001, dtype = tf.float32)\n",
    "#构建神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784,500],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([500])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([500,300],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([300])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([300,10],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10])+0.1)\n",
    "\n",
    "prediction = tf.nn.softmax(tf.matmul(L2_drop,W3)+b3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#二次代价函数\n",
    "#loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y,logits = prediction))\n",
    "\n",
    "train_step  = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "#变量初始化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #变量初始化\n",
    "    sess.run(init)\n",
    "    for epoch in range(50):\n",
    "        sess.run(tf.assign(lr,0.001*(0.95**epoch)))\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            feed_dict = {x:  batch_xs, y: batch_ys,keep_prob:1.0}\n",
    "            sess.run(train_step,feed_dict)\n",
    "        learning_rate = sess.run(lr)\n",
    "        #learning_rate = lr\n",
    "        test_acc = sess.run(accuracy,feed_dict = {x:mnist.test.images, y:mnist.test.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict = {x:mnist.train.images, y:mnist.train.labels,keep_prob:1.0})\n",
    "    #获得预测值\n",
    "        print(\"Iter\" + str(epoch)+ \", Testing Accuracy=\"+ str(test_acc)+\", Training Accuracy\"+ str(train_acc)+\", Learning Rate=\"+str(learning_rate))\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
